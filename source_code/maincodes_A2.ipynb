{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='mlflow-artifacts:/574122715825342513', creation_time=1694627434572, experiment_id='574122715825342513', last_update_time=1694627434572, lifecycle_stage='active', name='Run12', tags={}>"
      ]
     },
     "execution_count": 281,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#experiment tracking\n",
    "import mlflow\n",
    "import os\n",
    "# This the dockerized method.\n",
    "# We build two docker containers, one for python/jupyter and another for mlflow.\n",
    "# The url `mlflow` is resolved into another container within the same composer.\n",
    "mlflow.set_tracking_uri(\"http://mlflow:5000\")\n",
    "# In the dockerized way, the user who runs this code will be `root`.\n",
    "# The MLflow will also log the run user_id as `root`.\n",
    "# To change that, we need to set this environ[\"LOGNAME\"] to your name.\n",
    "os.environ[\"LOGNAME\"] = \"reza370\"\n",
    "mlflow.create_experiment(name=\"Run12\")  #create if you haven't create\n",
    "mlflow.set_experiment(experiment_name=\"Run12\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df_cars=pd.read_csv('Cars.csv')\n",
    "owner_coding = {\n",
    "    'First Owner': 1,\n",
    "    'Second Owner': 2,\n",
    "    'Third Owner': 3,\n",
    "    'Fourth & Above Owner': 4,\n",
    "    'Test Drive Car': 5\n",
    "}\n",
    "df_cars['owner'] = df_cars['owner'].map(owner_coding)\n",
    "#2\n",
    "df_cars = df_cars[df_cars['fuel'].isin(['Petrol', 'Diesel'])]\n",
    "#3\n",
    "df_cars.mileage = df_cars.mileage.str.split(expand=True)[0].astype(float)\n",
    "#4\n",
    "df_cars.engine = df_cars.engine.str.split(expand=True)[0].astype(float)\n",
    "#5\n",
    "df_cars.loc[df_cars['max_power'] == 'bph', 'max_power'] = ' bph'\n",
    "df_cars.max_power = df_cars.max_power.str.split(expand=True)[0].astype(float)\n",
    "#6\n",
    "df_cars.name=df_cars.name.str.split(expand=True)[0]\n",
    "#7\n",
    "df_cars = df_cars.drop(columns=['torque'])\n",
    "#8\n",
    "df_cars = df_cars[df_cars['owner'] != 5]\n",
    "#9\n",
    "import numpy as np\n",
    "df_cars['selling_price'] = np.log(df_cars['selling_price'])\n",
    "from datetime import datetime\n",
    "now = datetime.now()\n",
    "df_cars['car_age'] = int(now.strftime(\"%Y\")) - df_cars['year']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>year</th>\n",
       "      <th>selling_price</th>\n",
       "      <th>km_driven</th>\n",
       "      <th>fuel</th>\n",
       "      <th>seller_type</th>\n",
       "      <th>transmission</th>\n",
       "      <th>owner</th>\n",
       "      <th>mileage</th>\n",
       "      <th>engine</th>\n",
       "      <th>max_power</th>\n",
       "      <th>seats</th>\n",
       "      <th>car_age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Maruti</td>\n",
       "      <td>2014</td>\n",
       "      <td>13.017003</td>\n",
       "      <td>145500</td>\n",
       "      <td>Diesel</td>\n",
       "      <td>Individual</td>\n",
       "      <td>Manual</td>\n",
       "      <td>1</td>\n",
       "      <td>23.40</td>\n",
       "      <td>1248.0</td>\n",
       "      <td>74.00</td>\n",
       "      <td>5.0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Skoda</td>\n",
       "      <td>2014</td>\n",
       "      <td>12.821258</td>\n",
       "      <td>120000</td>\n",
       "      <td>Diesel</td>\n",
       "      <td>Individual</td>\n",
       "      <td>Manual</td>\n",
       "      <td>2</td>\n",
       "      <td>21.14</td>\n",
       "      <td>1498.0</td>\n",
       "      <td>103.52</td>\n",
       "      <td>5.0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Honda</td>\n",
       "      <td>2006</td>\n",
       "      <td>11.970350</td>\n",
       "      <td>140000</td>\n",
       "      <td>Petrol</td>\n",
       "      <td>Individual</td>\n",
       "      <td>Manual</td>\n",
       "      <td>3</td>\n",
       "      <td>17.70</td>\n",
       "      <td>1497.0</td>\n",
       "      <td>78.00</td>\n",
       "      <td>5.0</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Hyundai</td>\n",
       "      <td>2010</td>\n",
       "      <td>12.323856</td>\n",
       "      <td>127000</td>\n",
       "      <td>Diesel</td>\n",
       "      <td>Individual</td>\n",
       "      <td>Manual</td>\n",
       "      <td>1</td>\n",
       "      <td>23.00</td>\n",
       "      <td>1396.0</td>\n",
       "      <td>90.00</td>\n",
       "      <td>5.0</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Maruti</td>\n",
       "      <td>2007</td>\n",
       "      <td>11.775290</td>\n",
       "      <td>120000</td>\n",
       "      <td>Petrol</td>\n",
       "      <td>Individual</td>\n",
       "      <td>Manual</td>\n",
       "      <td>1</td>\n",
       "      <td>16.10</td>\n",
       "      <td>1298.0</td>\n",
       "      <td>88.20</td>\n",
       "      <td>5.0</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      name  year  selling_price  km_driven    fuel seller_type transmission  \\\n",
       "0   Maruti  2014      13.017003     145500  Diesel  Individual       Manual   \n",
       "1    Skoda  2014      12.821258     120000  Diesel  Individual       Manual   \n",
       "2    Honda  2006      11.970350     140000  Petrol  Individual       Manual   \n",
       "3  Hyundai  2010      12.323856     127000  Diesel  Individual       Manual   \n",
       "4   Maruti  2007      11.775290     120000  Petrol  Individual       Manual   \n",
       "\n",
       "   owner  mileage  engine  max_power  seats  car_age  \n",
       "0      1    23.40  1248.0      74.00    5.0        9  \n",
       "1      2    21.14  1498.0     103.52    5.0        9  \n",
       "2      3    17.70  1497.0      78.00    5.0       17  \n",
       "3      1    23.00  1396.0      90.00    5.0       13  \n",
       "4      1    16.10  1298.0      88.20    5.0       16  "
      ]
     },
     "execution_count": 283,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cars.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_cars[['max_power', 'mileage', 'car_age']]\n",
    "y = df_cars['selling_price']\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 370)\n",
    "X_train['max_power'].fillna(X_train['max_power'].median(), inplace=True)\n",
    "X_train['mileage'].fillna(X_train['mileage'].mean(), inplace=True)\n",
    "X_test['max_power'].fillna(X_train['max_power'].median(), inplace=True)\n",
    "X_test['mileage'].fillna(X_train['mileage'].mean(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>max_power</th>\n",
       "      <th>mileage</th>\n",
       "      <th>car_age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1937</th>\n",
       "      <td>112.0</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3966</th>\n",
       "      <td>67.0</td>\n",
       "      <td>20.630000</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6823</th>\n",
       "      <td>46.3</td>\n",
       "      <td>19.700000</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5447</th>\n",
       "      <td>82.0</td>\n",
       "      <td>19.394267</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4446</th>\n",
       "      <td>88.5</td>\n",
       "      <td>24.520000</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      max_power    mileage  car_age\n",
       "1937      112.0  14.000000       11\n",
       "3966       67.0  20.630000        5\n",
       "6823       46.3  19.700000       14\n",
       "5447       82.0  19.394267       15\n",
       "4446       88.5  24.520000        6"
      ]
     },
     "execution_count": 285,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((5619, 4), (2409, 4), (5619,), (2409,), (2409, 10))"
      ]
     },
     "execution_count": 286,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_names = ['max_power', 'mileage', 'car_age']\n",
    "label_name = 'selling_price'\n",
    "from   sklearn.preprocessing import StandardScaler\n",
    "from   sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "import numpy as np\n",
    "from   time import time\n",
    "import pandas as pd\n",
    "scaler  = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train) \n",
    "X_test  = scaler.transform(X_test)\n",
    "X_train = np.insert(X_train, 0, 1, axis=1)\n",
    "X_test  = np.insert(X_test, 0, 1, axis=1)\n",
    "y_train = np.array(y_train)\n",
    "y_test  = np.array(y_test)\n",
    "poly_X_train = PolynomialFeatures(degree = 2, include_bias=False).fit_transform(X_train)[:, [4,5,6,7,8,9,10,11,12,13]]\n",
    "poly_X_test = PolynomialFeatures(degree = 2, include_bias=False).fit_transform(X_test)[:, [4,5,6,7,8,9,10,11,12,13]]\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape,  poly_X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.574574</td>\n",
       "      <td>-1.361612</td>\n",
       "      <td>0.440258</td>\n",
       "      <td>0.330135</td>\n",
       "      <td>-0.782347</td>\n",
       "      <td>0.252961</td>\n",
       "      <td>1.853987</td>\n",
       "      <td>-0.599461</td>\n",
       "      <td>0.193827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.689880</td>\n",
       "      <td>0.311922</td>\n",
       "      <td>-1.037674</td>\n",
       "      <td>0.475934</td>\n",
       "      <td>-0.215189</td>\n",
       "      <td>0.715870</td>\n",
       "      <td>0.097295</td>\n",
       "      <td>-0.323673</td>\n",
       "      <td>1.076767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.271529</td>\n",
       "      <td>0.077173</td>\n",
       "      <td>1.179225</td>\n",
       "      <td>1.616785</td>\n",
       "      <td>-0.098127</td>\n",
       "      <td>-1.499418</td>\n",
       "      <td>0.005956</td>\n",
       "      <td>0.091004</td>\n",
       "      <td>1.390570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.268395</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.425547</td>\n",
       "      <td>0.072036</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.382610</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.032183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.085752</td>\n",
       "      <td>1.293829</td>\n",
       "      <td>-0.791352</td>\n",
       "      <td>0.007353</td>\n",
       "      <td>-0.110948</td>\n",
       "      <td>0.067860</td>\n",
       "      <td>1.673994</td>\n",
       "      <td>-1.023874</td>\n",
       "      <td>0.626238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5614</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.080132</td>\n",
       "      <td>-0.099520</td>\n",
       "      <td>-0.298708</td>\n",
       "      <td>0.006421</td>\n",
       "      <td>0.007975</td>\n",
       "      <td>0.023936</td>\n",
       "      <td>0.009904</td>\n",
       "      <td>0.029727</td>\n",
       "      <td>0.089226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5615</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.274015</td>\n",
       "      <td>0.458324</td>\n",
       "      <td>-1.283996</td>\n",
       "      <td>0.075084</td>\n",
       "      <td>-0.125588</td>\n",
       "      <td>0.351834</td>\n",
       "      <td>0.210061</td>\n",
       "      <td>-0.588487</td>\n",
       "      <td>1.648645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5616</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.273172</td>\n",
       "      <td>-0.200488</td>\n",
       "      <td>-0.791352</td>\n",
       "      <td>0.074623</td>\n",
       "      <td>0.054768</td>\n",
       "      <td>0.216175</td>\n",
       "      <td>0.040195</td>\n",
       "      <td>0.158656</td>\n",
       "      <td>0.626238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5617</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.274015</td>\n",
       "      <td>0.407841</td>\n",
       "      <td>-1.530318</td>\n",
       "      <td>0.075084</td>\n",
       "      <td>-0.111755</td>\n",
       "      <td>0.419330</td>\n",
       "      <td>0.166334</td>\n",
       "      <td>-0.624126</td>\n",
       "      <td>2.341873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5618</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.827565</td>\n",
       "      <td>-0.372132</td>\n",
       "      <td>0.686580</td>\n",
       "      <td>0.684863</td>\n",
       "      <td>0.307963</td>\n",
       "      <td>-0.568190</td>\n",
       "      <td>0.138482</td>\n",
       "      <td>-0.255499</td>\n",
       "      <td>0.471393</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5619 rows Ã— 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0         1         2         3         4         5         6  \\\n",
       "0     1.0  0.574574 -1.361612  0.440258  0.330135 -0.782347  0.252961   \n",
       "1     1.0 -0.689880  0.311922 -1.037674  0.475934 -0.215189  0.715870   \n",
       "2     1.0 -1.271529  0.077173  1.179225  1.616785 -0.098127 -1.499418   \n",
       "3     1.0 -0.268395  0.000000  1.425547  0.072036 -0.000000 -0.382610   \n",
       "4     1.0 -0.085752  1.293829 -0.791352  0.007353 -0.110948  0.067860   \n",
       "...   ...       ...       ...       ...       ...       ...       ...   \n",
       "5614  1.0 -0.080132 -0.099520 -0.298708  0.006421  0.007975  0.023936   \n",
       "5615  1.0 -0.274015  0.458324 -1.283996  0.075084 -0.125588  0.351834   \n",
       "5616  1.0 -0.273172 -0.200488 -0.791352  0.074623  0.054768  0.216175   \n",
       "5617  1.0 -0.274015  0.407841 -1.530318  0.075084 -0.111755  0.419330   \n",
       "5618  1.0 -0.827565 -0.372132  0.686580  0.684863  0.307963 -0.568190   \n",
       "\n",
       "             7         8         9  \n",
       "0     1.853987 -0.599461  0.193827  \n",
       "1     0.097295 -0.323673  1.076767  \n",
       "2     0.005956  0.091004  1.390570  \n",
       "3     0.000000  0.000000  2.032183  \n",
       "4     1.673994 -1.023874  0.626238  \n",
       "...        ...       ...       ...  \n",
       "5614  0.009904  0.029727  0.089226  \n",
       "5615  0.210061 -0.588487  1.648645  \n",
       "5616  0.040195  0.158656  0.626238  \n",
       "5617  0.166334 -0.624126  2.341873  \n",
       "5618  0.138482 -0.255499  0.471393  \n",
       "\n",
       "[5619 rows x 10 columns]"
      ]
     },
     "execution_count": 287,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(poly_X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "class LinearRegression(object):\n",
    "    \n",
    "    kfold = KFold(n_splits=2)\n",
    "            \n",
    "    def __init__(self, regularization, lr=0.001, method='batch', num_epochs=100, batch_size=50, cv=kfold, weight_init = 'zeros', momentum = 0.9):\n",
    "        self.lr             = lr\n",
    "        self.num_epochs     = num_epochs\n",
    "        self.batch_size     = batch_size\n",
    "        self.method         = method\n",
    "        self.cv             = cv\n",
    "        self.weight_init    = weight_init\n",
    "        self.momentum       = momentum\n",
    "        self.regularization = regularization\n",
    "        self.prev_grad      = None  \n",
    "\n",
    "    def mse(self, ytrue, ypred):\n",
    "        return ((ypred - ytrue) ** 2).sum() / ytrue.shape[0]\n",
    "    \n",
    "    #:::::::::::::::Assignment 2, Task1.1:Add a function r2 that compute the r2score.:::::::::::::\n",
    "    def r_squared(self, y_true, y_pred):\n",
    "        ss_residual = ((y_pred - y_true) ** 2).sum()\n",
    "        ss_total = (((y_true) - np.mean(y_true)) ** 2).sum()\n",
    "        r2 = 1 - (ss_residual / ss_total)\n",
    "        return r2\n",
    "    \n",
    "    def fit(self, X_train, y_train):\n",
    "            \n",
    "        #create a list of kfold scores\n",
    "        self.kfold_scores = list()\n",
    "        \n",
    "        #reset val loss\n",
    "        self.val_loss_old = np.infty\n",
    "\n",
    "        #kfold.split in the sklearn.....\n",
    "        #5 splits\n",
    "        for fold, (train_idx, val_idx) in enumerate(self.cv.split(X_train)):\n",
    "            \n",
    "            X_cross_train = X_train[train_idx]\n",
    "            y_cross_train = y_train[train_idx]\n",
    "            X_cross_val   = X_train[val_idx]\n",
    "            y_cross_val   = y_train[val_idx]\n",
    "                   \n",
    "    #::::::::::::::Assignment 2, Task1.2: Modify the class such that it allows the user to choose between zeros initialization or xavier.::::::::::::::\n",
    "\n",
    "            # \"Xavier/Glorot\" or \"zero\" initialization\n",
    "            if self.weight_init == 'xavier':\n",
    "                limit = np.sqrt(1 / (X_cross_train.shape[0]))\n",
    "                self.theta = np.random.uniform(-limit, limit, size=X_cross_train.shape[1])\n",
    "            if self.weight_init == 'zeros':\n",
    "                self.theta = np.zeros(X_cross_train.shape[1])\n",
    "                              \n",
    "            #define X_cross_train as only a subset of the data\n",
    "            #how big is this subset?  => mini-batch size ==> 50\n",
    "\n",
    "                     \n",
    "            #one epoch will exhaust the WHOLE training set\n",
    "            with mlflow.start_run(run_name=f\"Fold-{fold}\", nested=True):\n",
    "                \n",
    "                params = {\"method\": self.method, \"lr\": self.lr, \"reg\": type(self).__name__, \"initial weight\":self.weight_init}\n",
    "                mlflow.log_params(params=params)\n",
    "                \n",
    "                for epoch in range(self.num_epochs):\n",
    "                \n",
    "                    #with replacement or no replacement\n",
    "                    #with replacement means just randomize\n",
    "                    #with no replacement means 0:50, 51:100, 101:150, ......300:323\n",
    "                    #shuffle your index\n",
    "                    perm = np.random.permutation(X_cross_train.shape[0])\n",
    "                            \n",
    "                    X_cross_train = X_cross_train[perm]\n",
    "                    y_cross_train = y_cross_train[perm]\n",
    "                    \n",
    "                    if self.method == 'sto':\n",
    "                        for batch_idx in range(X_cross_train.shape[0]):\n",
    "                            X_method_train = X_cross_train[batch_idx].reshape(1, -1) #(11,) ==> (1, 11) ==> (m, n)\n",
    "                            y_method_train = y_cross_train[batch_idx] \n",
    "                            train_loss = self._train(X_method_train, y_method_train)\n",
    "                    elif self.method == 'mini':\n",
    "                        for batch_idx in range(0, X_cross_train.shape[0], self.batch_size):\n",
    "                            #batch_idx = 0, 50, 100, 150\n",
    "                            X_method_train = X_cross_train[batch_idx:batch_idx+self.batch_size, :]\n",
    "                            y_method_train = y_cross_train[batch_idx:batch_idx+self.batch_size]\n",
    "                            train_loss = self._train(X_method_train, y_method_train)\n",
    "                    else:\n",
    "                        X_method_train = X_cross_train\n",
    "                        y_method_train = y_cross_train\n",
    "                        train_loss = self._train(X_method_train, y_method_train)\n",
    "\n",
    "                    mlflow.log_metric(key=\"train_loss\", value=train_loss, step=epoch)\n",
    "\n",
    "                    yhat_val = self.predict(X_cross_val)\n",
    "                    val_loss_new = self.mse(y_cross_val, yhat_val)\n",
    "                    #val_loss_new = self.r_squared(y_cross_val, yhat_val)\n",
    "                    mlflow.log_metric(key=\"val_loss\", value=val_loss_new, step=epoch)\n",
    "                    \n",
    "                    #record dataset\n",
    "                    #mlflow_train_data = mlflow.data.from_numpy(features=X_method_train, targets=y_method_train)\n",
    "                    #mlflow.log_input(mlflow_train_data, context=\"training\")\n",
    "                    \n",
    "                    #mlflow_val_data = mlflow.data.from_numpy(features=X_cross_val, targets=y_cross_val)\n",
    "                    #mlflow.log_input(mlflow_val_data, context=\"validation\")\n",
    "                    \n",
    "                    #early stopping\n",
    "                    if np.allclose(val_loss_new, self.val_loss_old):\n",
    "                        break\n",
    "                    self.val_loss_old = val_loss_new\n",
    "            \n",
    "                self.kfold_scores.append(val_loss_new)\n",
    "                print(f\"Fold {fold}: {val_loss_new}\")\n",
    "    \n",
    "        \n",
    "                    \n",
    "    def _train(self, X, y):\n",
    "                    \n",
    "        yhat = self.predict(X)\n",
    "        m    = X.shape[0]        \n",
    "        grad = (1/m) * X.T @(yhat - y) + self.regularization.derivation(self.theta)\n",
    "        \n",
    "        #::::::::::::::Assignment 2, Task1.3: Modify the class such that it allows the user to choose momentum.::::::::::::::\n",
    "      \n",
    "        if self.prev_grad is None:\n",
    "            self.prev_grad = np.zeros_like(self.theta)  # Initialize velocity if it's None\n",
    "\n",
    "        # Update the velocity using momentum\n",
    "        self.prev_grad = self.momentum * self.prev_grad + (1 - self.momentum) * grad\n",
    "\n",
    "        # Update the parameters using the prev_grad and learning rate\n",
    "        self.theta = self.theta - self.lr * self.prev_grad\n",
    "        return self.mse(y, yhat) \n",
    "           \n",
    "        \n",
    "        #self.theta = self.theta - self.lr * grad\n",
    "        #return self.mse(y, yhat)\n",
    "        #return self.r_squared(y, yhat)\n",
    "\n",
    "    import matplotlib.pyplot as plt\n",
    "    def plot_feature_importance(self, feature_names):\n",
    "        # Create a list of tuples with feature names and coefficients\n",
    "        feature_coef = [(name, coef) for name, coef in zip(feature_names, self.theta)]\n",
    "\n",
    "        # Sort the list by coefficient magnitude\n",
    "        feature_coef.sort(key=lambda x: abs(X_train[1]), reverse=True)\n",
    "\n",
    "        # Extract sorted feature names and coefficients\n",
    "        sorted_feature_names, sorted_coefficients = zip(*feature_coef)\n",
    "\n",
    "        # Create a horizontal bar plot\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.barh(sorted_feature_names, sorted_coefficients, color='b')\n",
    "        plt.xlabel('Coefficient Magnitude')\n",
    "        plt.title('Feature Importance Based on Coefficients')\n",
    "        plt.gca().invert_yaxis()  # Invert the y-axis for better readability\n",
    "        plt.show()\n",
    "\n",
    "   \n",
    "    def predict(self, X):\n",
    "        return X @ self.theta  #===>(m, n) @ (n, )\n",
    "    \n",
    "    def _coef(self):\n",
    "        return self.theta[1:]  #remind that theta is (w0, w1, w2, w3, w4.....wn)\n",
    "                               #w0 is the bias or the intercept\n",
    "                               #w1....wn are the weights / coefficients / theta\n",
    "    def _bias(self):\n",
    "        return self.theta[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Normalpenalty:\n",
    "    def __init__(self, l):\n",
    "        self.l = 0 # lambda value\n",
    "        \n",
    "    def __call__(self, theta): #__call__ allows us to call class as method\n",
    "        return self.l * np.sum(np.abs(theta))\n",
    "        \n",
    "    def derivation(self, theta):\n",
    "        return self.l * np.sign(theta)\n",
    "\n",
    "class LassoPenalty:\n",
    "    \n",
    "    def __init__(self, l):\n",
    "        self.l = l # lambda value\n",
    "        \n",
    "    def __call__(self, theta): #__call__ allows us to call class as method\n",
    "        return self.l * np.sum(np.abs(theta))\n",
    "        \n",
    "    def derivation(self, theta):\n",
    "        return self.l * np.sign(theta)\n",
    "    \n",
    "class RidgePenalty:\n",
    "    \n",
    "    def __init__(self, l):\n",
    "        self.l = l\n",
    "        \n",
    "    def __call__(self, theta): #__call__ allows us to call class as method\n",
    "        return self.l * np.sum(np.square(theta))\n",
    "        \n",
    "    def derivation(self, theta):\n",
    "        return self.l * 2 * theta\n",
    "    \n",
    "class ElasticPenalty:\n",
    "    \n",
    "    def __init__(self, l = 0.1, l_ratio = 0.5):\n",
    "        self.l = l \n",
    "        self.l_ratio = l_ratio\n",
    "\n",
    "    def __call__(self, theta):  #__call__ allows us to call class as method\n",
    "        l1_contribution = self.l_ratio * self.l * np.sum(np.abs(theta))\n",
    "        l2_contribution = (1 - self.l_ratio) * self.l * 0.5 * np.sum(np.square(theta))\n",
    "        return (l1_contribution + l2_contribution)\n",
    "\n",
    "    def derivation(self, theta):\n",
    "        l1_derivation = self.l * self.l_ratio * np.sign(theta)\n",
    "        l2_derivation = self.l * (1 - self.l_ratio) * theta\n",
    "        return (l1_derivation + l2_derivation)\n",
    "\n",
    "class Normal(LinearRegression):\n",
    "    def __init__(self, method, lr, l):\n",
    "        self.regularization = Normalpenalty(l)\n",
    "        super().__init__(self.regularization, lr, method)\n",
    "\n",
    "class Lasso(LinearRegression):\n",
    "    \n",
    "    def __init__(self, method, lr, l):\n",
    "        self.regularization = LassoPenalty(l)\n",
    "        super().__init__(self.regularization, lr, method)\n",
    "        \n",
    "class Ridge(LinearRegression):\n",
    "    \n",
    "    def __init__(self, method, lr, l):\n",
    "        self.regularization = RidgePenalty(l)\n",
    "        super().__init__(self.regularization, lr, method)\n",
    "        \n",
    "class ElasticNet(LinearRegression):\n",
    "    \n",
    "    def __init__(self, method, lr, l, l_ratio=0.5):\n",
    "        self.regularization = ElasticPenalty(l, l_ratio)\n",
    "        super().__init__(self.regularization, lr, method)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [],
   "source": [
    "#helper function for looping classnames\n",
    "import sys\n",
    "\n",
    "def str_to_class(classname):\n",
    "    return getattr(sys.modules[__name__], classname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** Polynomial *****\n",
      "Fold 0: 0.12492895694242856\n",
      "Fold 1: 0.35104507557664705\n",
      "Test mse:  0.20342088940436506\n",
      "Test R2:  0.7087852691551437\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/site-packages/_distutils_hack/__init__.py:18: UserWarning: Distutils was imported before Setuptools, but importing Setuptools also replaces the `distutils` module in `sys.modules`. This may lead to undesirable behaviors or errors. To avoid these issues, avoid using distutils directly, ensure that setuptools is installed in the traditional way (e.g. not an editable install), and/or make sure that setuptools is always imported before distutils.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/_distutils_hack/__init__.py:33: UserWarning: Setuptools is replacing distutils.\n",
      "  warnings.warn(\"Setuptools is replacing distutils.\")\n"
     ]
    }
   ],
   "source": [
    "regs = [\"Normal\"]\n",
    "\n",
    "for reg in regs:\n",
    "\n",
    "    params = {\"method\": \"batch\", \"lr\": 0.1, \"l\": 0,}\n",
    "    mlflow.start_run(run_name=f\"method-{params['method']}-lr-{params['lr']}-reg-{'polynomial'}-weight_init-{'zeros'}\", nested=True)\n",
    "    print(\"*\"*5, \"Polynomial\", \"*\"*5)\n",
    "     # #######\n",
    "    type_of_regression = str_to_class(reg)    \n",
    "    model = type_of_regression(**params)\n",
    "    model.fit(poly_X_train, y_train)\n",
    "    yhat = model.predict(poly_X_test)\n",
    "    mse  = model.mse(yhat, y_test)\n",
    "    r_squared = model.r_squared(y_test, yhat)\n",
    "    print(\"Test mse: \", mse)\n",
    "    mlflow.log_metric(key=\"mse\", value=mse)\n",
    "    print(\"Test R2: \", r_squared)\n",
    "    \n",
    "    \n",
    "    mlflow.log_metric(key=\"r_squared\", value=r_squared)\n",
    "    signature = mlflow.models.infer_signature(poly_X_train, model.predict(poly_X_train))\n",
    "    mlflow.sklearn.log_model(model, artifact_path='model', signature=signature)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** Normal *****\n",
      "Fold 0: 0.11551339462022964\n",
      "Fold 1: 0.11873579386167558\n",
      "Test mse:  0.11982876917127333\n",
      "Test R2:  0.8284546741297751\n",
      "***** Ridge *****\n",
      "Fold 0: 4.608039653815789\n",
      "Fold 1: 4.505006041499877\n",
      "Test mse:  4.524106583827496\n",
      "Test R2:  -5.476652840229373\n",
      "***** Lasso *****\n",
      "Fold 0: 0.13757085584641046\n",
      "Fold 1: 0.13502453260933295\n",
      "Test mse:  0.13923675066204289\n",
      "Test R2:  0.800670457264803\n",
      "***** ElasticNet *****\n",
      "Fold 0: 0.519688513075041\n",
      "Fold 1: 0.49071534716041887\n",
      "Test mse:  0.49840650444739304\n",
      "Test R2:  0.2864876539033623\n"
     ]
    }
   ],
   "source": [
    "regs = [\"Normal\", \"Ridge\", \"Lasso\", \"ElasticNet\"]\n",
    "\n",
    "for reg in regs:\n",
    "\n",
    "    params = {\"method\": \"batch\", \"lr\": 0.1, \"l\": 0.1,}\n",
    "    mlflow.start_run(run_name=f\"method-{params['method']}-lr-{params['lr']}-reg-{reg}-weight_init-{'zeros'}\", nested=True)\n",
    "    print(\"*\"*5, reg, \"*\"*5)\n",
    "     # #######\n",
    "    type_of_regression = str_to_class(reg)    #Ridge, Lasso, ElasticNet\n",
    "    model = type_of_regression(**params)\n",
    "    model.fit(X_train, y_train)\n",
    "    yhat = model.predict(X_test)\n",
    "    mse  = model.mse(yhat, y_test)\n",
    "    r_squared = model.r_squared(y_test, yhat)\n",
    "    print(\"Test mse: \", mse)\n",
    "    mlflow.log_metric(key=\"mse\", value=mse)\n",
    "    print(\"Test R2: \", r_squared)\n",
    "\n",
    "    \n",
    "    mlflow.log_metric(key=\"r_squared\", value=r_squared)\n",
    "    signature = mlflow.models.infer_signature(X_train, model.predict(X_train))\n",
    "    mlflow.sklearn.log_model(model, artifact_path='model', signature=signature)\n",
    "\n",
    "    # #######\n",
    "\n",
    "    mlflow.end_run()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
